<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>

<div class="sidebar">
<a href="../index.html">Home</a>
<a href="topic.html">Technology/Topic</a>
<a href="opportunities.html">Opportunities</a>
<a href="risks.html">Risks</a>
<a href="Choices.html">Choices</a>
<a class="active" href="#Ethics">Ethics</a>
<a href="references.html">References</a>
<a href="process.html">Process Support</a>
</div>

<div class="content"><head>
  <title>ethics</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<!-- Main content -->
<h1>Ethical Issues and Reflections</h1>


</ul><h4><p>Ethical issues relating to social media algorithms (Umar)<p></h4>

<p>Algorithms have largely changed the way we use social media. There is no doubt that that they are very useful in different ways. I myself have found that 
algorithms improve my experience using certain platforms. For example, when searching for fan art of one of my favourite fictional characters on the Pinterest
 app, I found that my “browse” page, in other words, the home page of the app, had been filled with lots of images that matched what I searched for. This
 reduces the need to search for certain content again, as it just shows up on the home page when you open the app. Typically, algorithms also put posts from a 
 user’s family and friends at the top of their home page, which makes it a lot easier for them to keep up with each other. Section 1.1 of the ACM Code of 
 Ethics states that computing professionals should contribute both to society, and the well-being of humans. (ACM Code of Ethics and Professional Conduct, 
 2018) I believe algorithms at least partially demonstrate this as they have the potential to improve interactions among users.</p>
<p>However, there is also potential for algorithms to harm people, especially those that are too absorbed in social media. Flawed algorithm design has caused 
issues that should not be ignored, such as addiction, damage to mental health, especially among teens, and twisting people’s views with misinformation and
 disinformation, a result of Facebook’s engagement-based algorithm. Internal documents leaked by Facebook whistle-blower Frances Haugen exposed the corruption
 behind the company now known as Meta. Despite knowing that their Facebook and Instagram algorithms brought such harm to its users, they deliberately chose
 not to do anything to solve the issue, choosing to prioritise profit over people. This goes against section 1.2 of the ACM Code of Ethics, which states that 
 computing professionals should avoid harm. In this case, “harm” is the mental damage done to users of social media. This section also states that if any harm 
 is done by the system intentionally, those responsible have an obligation to ethically justify said harm and ensure that it is minimised. Facebook choosing 
 not to disclose their internal research documents regarding mental health issues also violates section 1.3 of the ACM Code of Ethics, which requires 
 computing professionals to be honest and trustworthy by disclosing potential problems and limitations to any parties involved. Additionally, algorithms 
 rely on data gathered from users to sort their feed, which revolves around their personal interests. Social media companies have an obligation to keep 
 that data safe and not distribute it to third parties without the involved users’ permission, as described in section 1.7 of the ACM Code of Ethics. 
 However, events in recent years have seen Facebook violate that section, like the Cambridge Analytica scandal, which involved millions of users’ personal
 data being leaked to the political firm for targeted advertising. These incidents have caused a lot of people to lose trust in social media companies.</p>
<p>With the way that social media algorithms are designed now, they pose too many risks to communities and individuals as compared to the opportunities they
 bring. Because social media companies have failed to follow basic ethical practices and protect their users from their harmful algorithm design, a lot of
 work needs to be done to improve them. As the number of total users grows, it is very likely that the number of people being harmed by them will also grow
 if there is no change within these companies. One proposed solution involves the establishment of an “algorithm auditor” government system which would
 legally require social media algorithms to meet safety and transparency standards. This is a good solution because it is not likely that social media 
 companies will solve the issue on their own, especially given the fact that Facebook chose not to disclose their research on mental harm among their users
 or make changes to their business practices before that information was leaked. It is also important that parents play a role in protecting their kids
 from the harmful effects of being too absorbed in social media, as younger people have been proven to be the most affected.</p>



<address>Made 26 May 2022<br>
  by Umar Muhammad Shameem.</address>
 
 </div></html>