<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>

<div class="sidebar">
<a href="../index.html">Home</a>
<a href="topic.html">Technology/Topic</a>
<a href="opportunities.html">Opportunities</a>
<a class="active" href="#Risks">Risks</a>
<a href="choices.html">Choices</a>
<a href="ethics.html">Ethics</a>
<a href="references.html">References</a>
<a href="process.html">Process Support</a>
</div>

<div class="content"><head>
  <title>Risks</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
<!-- Main content -->
<h1>Technology Risks</h1>


</ul><h4><p>The risks that social media algorithms pose.<p></h4>

<p>Social media algorithms can and have been proven to pose risks to individuals and communities that use them if the design is flawed. In 2021, former 
Facebook product manager Frances Haugen leaked the company’s internal documents which exposed their business practices. These documents revealed that Facebook
 prioritized its growth rather than the safety of the users. The platform was found to have an engagement-based algorithm which rewarded content that 
 generated more interactions. Because the company chose not to implement any kind of safeguards, the algorithm amplified the spread of harmful and divisive
 content such as misinformation, hate speech, and incited violence, and this information, despite being known to the company, was never disclosed to the
 public or to government officials. (McCluskey, 2022) One such occurrence is the “explosion” of vaccine misinformation in New Zealand during the Covid-19 
 pandemic, which led to the anti-vaccine-mandate protests outside Parliament. Pages and accounts on social media that spread misinformation have grown 
 largely in follower and subscriber count, with Counterspin Media being one of those pages, having 18,000 subscribers on Telegram. It is believed that this
 large volume of misinformation will continue to have an impact on social cohesion in New Zealand in the future. (McCann, 2022)
</p>
<p>Algorithms are designed to be addictive, and this is especially a risk for younger people. According to research done by Statista in 2019, 40% of U.S. 
based internet users between the ages of  18 and 22 years old felt that they were addicted to social media, with 37% of users between 23 and 38 years old 
feeling addicted. (Social Media Addiction By Age, 2019) Addictions have been shown to form the business model for social media companies, especially in 
Facebook’s case. This is because the longer people spend scrolling through social media, the more advertisements they see, therefore generating more money for
 those companies. (Patel, 2022) When this information was disclosed following the leak of Facebook’s internal documents, the company came under fire for 
 prioritizing profit over people, and the “addictive” algorithms had been compared to Big Tobacco. The addiction to social media can also lead to mental 
 health issues. According to the leaked Facebook documents, this was also the case with Instagram, which is owned by Facebook (now known as Meta). Addictive 
 features such as the “Explore” page play a large role in showing harmful content to children and teenagers, leading to issues with mental health and body 
 image issues. Facebook’s internal research showed that 13.5% of teenage girls in the U.K. had more frequent suicidal thoughts once they started using 
 Instagram. 17% of those surveyed teens also said that using Instagram made their eating disorders worse, and 32% reported that, despite already feeling bad 
 about their bodies, using Instagram made them feel even worse. (Allyn, 2021) Furthermore, a study done by JAMA Psychiatry in 2019 shows that teens who spend 
 more than 3 hours on social media are more likely to struggle with issues such as depression, anxiety, and low self-esteem. (Riehm et al., 2019)
 </p>
<p>Social media companies store a lot of the users’ personal data to be used by their algorithms, and with that comes concerns about data privacy, and whether 
that personal data is being kept safe and is being used solely for the benefit of the users, or illegally being distributed to third parties. Facebook, for 
example, has failed to keep personal data safe on multiple occasions, one of those being the data breach that occurred in 2021, leaking the data of over 500 
million users. Another instance where this personal data was accessed illegally was the Cambridge Analytica scandal, which saw the data of up to 87 million 
Facebook users leaked to Cambridge Analytica, a political firm responsible for work behind the Trump campaign. This data was harvested by Dr Aleksandr Kogan 
through a personality/political survey app which required users to log in using Facebook, and collected data from the test-takers’ profiles such as likes and 
personal information, as well as their friends’ data. This data was matched by algorithms with the survey results and voter records, then used to create 
personality profiles which the firm would then use for targeted advertising to help Donald Trump win the 2016 U.S. Election. (Hern, 2018)
</p>

<address>Made 26 May 2022<br>
  by Umar Muhammad Shameem.</address>
 
</div></html>