<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>

<div class="sidebar">
<a href="../index.html">Home</a>
<a href="topic.html">Technology/Topic</a>
<a href="opportunities.html">Opportunities</a>
<a href="risks.html">Risks</a>
<a class="active" href="#Choices">Choices</a>
<a href="ethics.html">Ethics</a>
<a href="references.html">References</a>
<a href="process.html">Process Support</a>
</div>

<div class="content"><head>
  <title>choices</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>

<!-- Main content -->
<h1>Technology Choices</h1>


</ul><h4><p>How algorithms will have an impact on the future and what can be done about it.<p></h4>

<p>Social media is growing in popularity, just as the algorithms continue to evolve. Unless social media companies are held to account, and significant change 
is made to those platforms and how the algorithms are designed, the risks they pose to communities and individuals will continue, if not get worse. As of 
January 2022, Facebook is the most popular social media platform with 2.91 billion monthly active users. The overall number of social media users is expected 
to hit 4.41 billion globally by 2025. As this number goes up, so will the number of people affected by it in negative ways. (Social Media Addiction By Age, 
2021)
</p>
<p>It is possible to reduce the harm done by social media by fixing their manipulative and addictive design, and one of those ways is by improving personal 
data privacy and protection. Currently, users of social media lack the freedom to control their data as they are always being monitored, and their data is 
being harvested by companies that determine what they can and cannot see online. A possible solution to this is implementing rules that allow the users to 
control what data they would allow the company to access. For example, one user could choose not to allow the company to monitor the time they spend online 
or their engagement on certain posts. Additionally, those rules could also restrict how much data can be used by third parties such as advertisers. 
Implementing these rules could also mean that, should a data breach occur, users would have less, if not none of their data accessed without their permission,
 like what happened with the Cambridge Analytica scandal, which allowed millions of psychological profiles to be built without the knowledge of the people 
 involved. Addictive design features are also important to consider when reducing the harmful effects of social media algorithms. A majority of platforms such 
 as Reddit, Facebook and Twitter have features such as infinite scrolling and refreshing, a function that refreshes a user’s feed with new content tailored to 
 their interests. These features lead to “doom-scrolling” which means to scroll without an end in sight, leading to addiction. Putting a limit on how much 
 users can scroll is one way to prevent addiction. (Cocchiarella, 2021)
 </p>
 <p>Combating the spread of misinformation and other types of harmful content is important when it comes to preventing harm to communities and to the mental 
 health of individuals. Social media companies need to be held to account and start to do a better job of cracking down on harmful content on their platforms,
 such as hate speech, images from influencers that lead to body image issues, and misinformation that divides the community on various issues, because a lot 
 of this content still goes unchecked. The rate at which toxic users are being banned and harmful posts are being removed needs to keep up with how regularly 
 such content is being posted online. It may not be likely that social media companies will solve the issue on their own given the fact that the company now
 known as Meta knew long before being exposed for their ignorant business practice that Facebook and Instagram were harming the mental health of teenagers, 
 so government regulations should be made to keep algorithms in check. In light of the disturbing revelations from Facebook’s leaked internal documents, there
 have been talks in the U.S. government to establish a “government system of algorithm auditors”. These auditors, having the right expertise and authority to
 do so, would require social media companies to ensure that their algorithms meet basic safety and transparency standards. As younger people make up the 
 largest victim group of social media, until proper government regulations are in place, parents can help prevent mental harm by limiting the amount of time 
 their kids spend on social media, as well as monitor their activity online and have discussions with them around issues such as body image and how various 
 types of content can make them feel about themselves. (Feldsher, 2021)
 </p>

<address>Made 26 May 2022<br>
  by Umar Muhammad Shameem.</address>
 
</div></html>